{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimage_dir = '/kaggle/input/ocular-disease-recognition-odir5k/preprocessed_images/'\nbase_dir = '/kaggle/input/ocular-disease-recognition-odir5k/'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-16T20:19:24.015559Z","iopub.execute_input":"2022-04-16T20:19:24.015822Z","iopub.status.idle":"2022-04-16T20:19:24.020706Z","shell.execute_reply.started":"2022-04-16T20:19:24.015793Z","shell.execute_reply":"2022-04-16T20:19:24.019667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport pandas as pd\n#from utils import extract_target_array","metadata":{"execution":{"iopub.status.busy":"2022-04-16T20:19:24.202929Z","iopub.execute_input":"2022-04-16T20:19:24.203164Z","iopub.status.idle":"2022-04-16T20:19:24.20715Z","shell.execute_reply.started":"2022-04-16T20:19:24.203136Z","shell.execute_reply":"2022-04-16T20:19:24.206366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_info = pd.read_csv(base_dir+'full_df.csv')\ntargets = data_info['target']","metadata":{"execution":{"iopub.status.busy":"2022-04-16T20:19:25.126549Z","iopub.execute_input":"2022-04-16T20:19:25.126814Z","iopub.status.idle":"2022-04-16T20:19:25.187923Z","shell.execute_reply.started":"2022-04-16T20:19:25.126784Z","shell.execute_reply":"2022-04-16T20:19:25.187229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cateract = data_info[data_info['C']==1]\nnormal = data_info[data_info['N']==1]","metadata":{"execution":{"iopub.status.busy":"2022-04-16T20:19:38.061451Z","iopub.execute_input":"2022-04-16T20:19:38.061716Z","iopub.status.idle":"2022-04-16T20:19:38.070067Z","shell.execute_reply.started":"2022-04-16T20:19:38.061685Z","shell.execute_reply":"2022-04-16T20:19:38.069368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"normal=normal.sample(frac=0.25,random_state=200) #random state is a seed value\nnormal","metadata":{"execution":{"iopub.status.busy":"2022-04-16T19:06:04.564427Z","iopub.execute_input":"2022-04-16T19:06:04.564714Z","iopub.status.idle":"2022-04-16T19:06:04.588982Z","shell.execute_reply.started":"2022-04-16T19:06:04.564682Z","shell.execute_reply":"2022-04-16T19:06:04.588179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_info = pd.concat([cateract,normal])","metadata":{"execution":{"iopub.status.busy":"2022-04-16T19:06:08.754631Z","iopub.execute_input":"2022-04-16T19:06:08.754895Z","iopub.status.idle":"2022-04-16T19:06:08.7632Z","shell.execute_reply.started":"2022-04-16T19:06:08.754866Z","shell.execute_reply":"2022-04-16T19:06:08.761583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df=data_info.sample(frac=0.90,random_state=200) #random state is a seed value\ntest_df=data_info.drop(train_df.index)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T19:06:14.278319Z","iopub.execute_input":"2022-04-16T19:06:14.27909Z","iopub.status.idle":"2022-04-16T19:06:14.287616Z","shell.execute_reply.started":"2022-04-16T19:06:14.279048Z","shell.execute_reply":"2022-04-16T19:06:14.2868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"![](http://)","metadata":{}},{"cell_type":"code","source":"def extract_target(target):\n    target = target.replace('[','').replace(']','')\n    target = target.split(',')\n    target = [int(t.strip()) for t in target]\n    return np.argmax(np.array(target))\n    return target","metadata":{"execution":{"iopub.status.busy":"2022-04-16T19:06:16.971487Z","iopub.execute_input":"2022-04-16T19:06:16.973295Z","iopub.status.idle":"2022-04-16T19:06:16.982276Z","shell.execute_reply.started":"2022-04-16T19:06:16.973247Z","shell.execute_reply":"2022-04-16T19:06:16.981278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_images(image_fnames,images_dir):\n    images = []\n    n = 0\n    for fname in image_fnames:\n        image = cv2.imread(images_dir+fname)\n        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n        images.append(image)\n        print(n); n+=1\n        print(image.shape)\n        if n > 500:\n            break\n    return np.array(images)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T19:06:17.427265Z","iopub.execute_input":"2022-04-16T19:06:17.428283Z","iopub.status.idle":"2022-04-16T19:06:17.43777Z","shell.execute_reply.started":"2022-04-16T19:06:17.428234Z","shell.execute_reply":"2022-04-16T19:06:17.437011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def _bytes_feature(value):\n    if isinstance(value, type(tf.constant(0))): # if value ist tensor\n        value = value.numpy() # get value of tensor\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _float_feature(value):\n    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n\ndef _int64_feature(value):\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\ndef serialize_array(array):\n    array = tf.io.serialize_tensor(array)\n    return array","metadata":{"execution":{"iopub.status.busy":"2022-04-16T19:06:17.947046Z","iopub.execute_input":"2022-04-16T19:06:17.947735Z","iopub.status.idle":"2022-04-16T19:06:17.95405Z","shell.execute_reply.started":"2022-04-16T19:06:17.947697Z","shell.execute_reply":"2022-04-16T19:06:17.953165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def parse_single_image(image, label):\n  #define the dictionary -- the structure -- of our single example\n    data = {\n            'height' : _int64_feature(image.shape[0]),\n            'width' : _int64_feature(image.shape[1]),\n            'depth' : _int64_feature(image.shape[2]),\n            'raw_image' : _bytes_feature(serialize_array(image)),\n            'label' : _int64_feature(label)\n        }\n   #create an Example, wrapping the single features\n    output = tf.train.Example(features=tf.train.Features(feature=data))\n    return output","metadata":{"execution":{"iopub.status.busy":"2022-04-16T19:06:18.200848Z","iopub.execute_input":"2022-04-16T19:06:18.201231Z","iopub.status.idle":"2022-04-16T19:06:18.20665Z","shell.execute_reply.started":"2022-04-16T19:06:18.201196Z","shell.execute_reply":"2022-04-16T19:06:18.205822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def parse_tfr_element(element):\n  #use the same structure as above; it's kinda an outline of the structure we now want to create\n    data = {\n      'height': tf.io.FixedLenFeature([], tf.int64),\n      'width':tf.io.FixedLenFeature([], tf.int64),\n      'label':tf.io.FixedLenFeature([], tf.int64),\n      'raw_image' : tf.io.FixedLenFeature([], tf.string),\n      'depth':tf.io.FixedLenFeature([], tf.int64),\n    }\n    content = tf.io.parse_single_example(element, data)\n  \n    height = content['height']\n    width = content['width']\n    depth = content['depth']\n    label = content['label']\n    raw_image = content['raw_image']\n    #get our 'feature'-- our image -- and reshape it appropriately\n    feature = tf.io.parse_tensor(raw_image, out_type=tf.uint8)\n    feature = tf.reshape(feature, shape=[height,width,depth])\n    feature = tf.image.resize(feature, [256, 256])/255\n    return (feature, label)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T19:06:19.518089Z","iopub.execute_input":"2022-04-16T19:06:19.518817Z","iopub.status.idle":"2022-04-16T19:06:19.526108Z","shell.execute_reply.started":"2022-04-16T19:06:19.518777Z","shell.execute_reply":"2022-04-16T19:06:19.52526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def images2tfrecord(df,filename):\n    #\n    filename= filename+\".tfrecords\"\n    writer = tf.io.TFRecordWriter(filename) #create a writer that'll store our data to disk\n    count = 0\n    for idx,row in df.iterrows():\n        image = cv2.imread(image_dir+row['filename'])\n        current_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        current_label = row['N']\n        #current_label = extract_target(current_label)\n        out = parse_single_image(image=current_image, label=current_label)\n        writer.write(out.SerializeToString())\n        count += 1\n    writer.close()\n    print(f\"Wrote {count} elements to TFRecord\")\n    return count ","metadata":{"execution":{"iopub.status.busy":"2022-04-16T19:09:04.630592Z","iopub.execute_input":"2022-04-16T19:09:04.630876Z","iopub.status.idle":"2022-04-16T19:09:04.637332Z","shell.execute_reply.started":"2022-04-16T19:09:04.630844Z","shell.execute_reply":"2022-04-16T19:09:04.636294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images2tfrecord(train_df,'train_data_record')\nimages2tfrecord(test_df,'test_data_record')","metadata":{"execution":{"iopub.status.busy":"2022-04-16T19:09:07.756686Z","iopub.execute_input":"2022-04-16T19:09:07.756954Z","iopub.status.idle":"2022-04-16T19:09:14.951098Z","shell.execute_reply.started":"2022-04-16T19:09:07.756922Z","shell.execute_reply":"2022-04-16T19:09:14.950354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_image_dataset_train = tf.data.TFRecordDataset('OCCULAR_DISEASE_DATA/train_data_record.tfrecords')\n\n# Create a dictionary describing the features.\nimage_feature_description = {\n    'height': tf.io.FixedLenFeature([], tf.int64),\n    'width': tf.io.FixedLenFeature([], tf.int64),\n    'depth': tf.io.FixedLenFeature([], tf.int64),\n    'label': tf.io.FixedLenFeature([], tf.int64),\n    'image_raw': tf.io.FixedLenFeature([], tf.string),\n}\n\ndef _parse_image_function(example_proto):\n  # Parse the input tf.train.Example proto using the dictionary above.\n  return tf.io.parse_single_example(example_proto, image_feature_description)\n\nparsed_image_dataset_train = raw_image_dataset_train.map(_parse_image_function)\nraw_image_dataset_test = tf.data.TFRecordDataset('test_data_record.tfrecords')\nparsed_image_dataset_test = raw_image_dataset_test.map(_parse_image_function)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-16T19:09:31.56905Z","iopub.execute_input":"2022-04-16T19:09:31.569342Z","iopub.status.idle":"2022-04-16T19:09:31.612496Z","shell.execute_reply.started":"2022-04-16T19:09:31.569311Z","shell.execute_reply":"2022-04-16T19:09:31.611813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_dataset(filename):\n  #create the dataset\n    dataset = tf.data.TFRecordDataset(filename)\n\n  #pass every single feature through our mapping function\n    dataset = dataset.map(\n      parse_tfr_element\n  ) \n    return dataset","metadata":{"execution":{"iopub.status.busy":"2022-04-16T19:09:33.929525Z","iopub.execute_input":"2022-04-16T19:09:33.929958Z","iopub.status.idle":"2022-04-16T19:09:33.934261Z","shell.execute_reply.started":"2022-04-16T19:09:33.929921Z","shell.execute_reply":"2022-04-16T19:09:33.933413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"map_dataset_train = get_dataset('train_data_record.tfrecords')\nmap_dataset_test = get_dataset('test_data_record.tfrecords')","metadata":{"execution":{"iopub.status.busy":"2022-04-16T19:09:34.836394Z","iopub.execute_input":"2022-04-16T19:09:34.837003Z","iopub.status.idle":"2022-04-16T19:09:34.878543Z","shell.execute_reply.started":"2022-04-16T19:09:34.836965Z","shell.execute_reply":"2022-04-16T19:09:34.877889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for image_features in map_dataset_train:\n    image_raw = image_features[0].numpy()\n    label = image_features[1]\n    print(label)\n    plt.imshow(image_raw)\n    break\n    # to iterate over the dataset","metadata":{"execution":{"iopub.status.busy":"2022-04-16T19:09:36.730839Z","iopub.execute_input":"2022-04-16T19:09:36.731143Z","iopub.status.idle":"2022-04-16T19:09:37.007754Z","shell.execute_reply.started":"2022-04-16T19:09:36.731092Z","shell.execute_reply":"2022-04-16T19:09:37.00697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batched_dataset_train = map_dataset_train.batch(32, drop_remainder=True)\nbatched_dataset_test = map_dataset_test.batch(32, drop_remainder=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T19:09:39.696555Z","iopub.execute_input":"2022-04-16T19:09:39.696817Z","iopub.status.idle":"2022-04-16T19:09:39.704354Z","shell.execute_reply.started":"2022-04-16T19:09:39.696787Z","shell.execute_reply":"2022-04-16T19:09:39.703178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# MODEL TIME","metadata":{"execution":{"iopub.status.busy":"2022-04-16T19:09:40.033838Z","iopub.execute_input":"2022-04-16T19:09:40.03408Z","iopub.status.idle":"2022-04-16T19:09:40.038372Z","shell.execute_reply.started":"2022-04-16T19:09:40.034052Z","shell.execute_reply":"2022-04-16T19:09:40.037357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D,Flatten, MaxPool2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import sparse_categorical_crossentropy, CategoricalCrossentropy, binary_crossentropy","metadata":{"execution":{"iopub.status.busy":"2022-04-16T19:09:52.427811Z","iopub.execute_input":"2022-04-16T19:09:52.428305Z","iopub.status.idle":"2022-04-16T19:09:52.433824Z","shell.execute_reply.started":"2022-04-16T19:09:52.428262Z","shell.execute_reply":"2022-04-16T19:09:52.432876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model = tf.keras.applications.VGG19(input_shape=(256,256,3),\n                                               include_top=False,\n                                               weights='imagenet')","metadata":{"execution":{"iopub.status.busy":"2022-04-16T19:12:57.443535Z","iopub.execute_input":"2022-04-16T19:12:57.444362Z","iopub.status.idle":"2022-04-16T19:12:58.696788Z","shell.execute_reply.started":"2022-04-16T19:12:57.444323Z","shell.execute_reply":"2022-04-16T19:12:58.696041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs = tf.keras.Input(shape=(256, 256, 3))\nprediction_layer = tf.keras.layers.Dense(1,activation='sigmoid')\nfc_layer = tf.keras.layers.Dense(256,activation='relu')\nx = base_model(inputs, training=False)\nfor layer in base_model.layers:\n    layer.trainable = False\n    \nx = tf.keras.layers.Dropout(0.2)(x)\nx = Flatten()(x)\nx = fc_layer(x)\n#outputs = prediction_layer(x)\noutputs = prediction_layer(x)\nmodel = tf.keras.Model(inputs, outputs)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T19:13:30.193058Z","iopub.execute_input":"2022-04-16T19:13:30.193337Z","iopub.status.idle":"2022-04-16T19:13:30.275461Z","shell.execute_reply.started":"2022-04-16T19:13:30.193308Z","shell.execute_reply":"2022-04-16T19:13:30.274681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam',loss=binary_crossentropy,metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-04-16T19:13:31.206531Z","iopub.execute_input":"2022-04-16T19:13:31.209734Z","iopub.status.idle":"2022-04-16T19:13:31.226653Z","shell.execute_reply.started":"2022-04-16T19:13:31.209678Z","shell.execute_reply":"2022-04-16T19:13:31.225619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-16T19:13:32.401312Z","iopub.execute_input":"2022-04-16T19:13:32.401872Z","iopub.status.idle":"2022-04-16T19:13:32.411663Z","shell.execute_reply.started":"2022-04-16T19:13:32.401833Z","shell.execute_reply":"2022-04-16T19:13:32.410967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(batched_dataset_train,epochs=20)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T19:13:39.083062Z","iopub.execute_input":"2022-04-16T19:13:39.083403Z","iopub.status.idle":"2022-04-16T19:14:27.862544Z","shell.execute_reply.started":"2022-04-16T19:13:39.083368Z","shell.execute_reply":"2022-04-16T19:14:27.861858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(batched_dataset_test)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T19:14:29.895823Z","iopub.execute_input":"2022-04-16T19:14:29.896226Z","iopub.status.idle":"2022-04-16T19:14:30.316936Z","shell.execute_reply.started":"2022-04-16T19:14:29.896192Z","shell.execute_reply":"2022-04-16T19:14:30.315984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('/kaggle/working/model1.h5')","metadata":{"execution":{"iopub.status.busy":"2022-04-16T19:16:06.202097Z","iopub.execute_input":"2022-04-16T19:16:06.202786Z","iopub.status.idle":"2022-04-16T19:16:06.592342Z","shell.execute_reply.started":"2022-04-16T19:16:06.202749Z","shell.execute_reply":"2022-04-16T19:16:06.591458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2022-04-16T19:16:15.457768Z","iopub.execute_input":"2022-04-16T19:16:15.45839Z","iopub.status.idle":"2022-04-16T19:16:16.163003Z","shell.execute_reply.started":"2022-04-16T19:16:15.458347Z","shell.execute_reply":"2022-04-16T19:16:16.162174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}