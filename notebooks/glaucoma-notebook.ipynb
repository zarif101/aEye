{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimage_dir = '/kaggle/input/ocular-disease-recognition-odir5k/preprocessed_images/'\nbase_dir = '/kaggle/input/ocular-disease-recognition-odir5k/'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-16T20:47:25.989516Z","iopub.execute_input":"2022-04-16T20:47:25.990076Z","iopub.status.idle":"2022-04-16T20:47:26.003148Z","shell.execute_reply.started":"2022-04-16T20:47:25.989974Z","shell.execute_reply":"2022-04-16T20:47:26.001886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\n#from utils import extract_target_array","metadata":{"execution":{"iopub.status.busy":"2022-04-16T20:47:26.010958Z","iopub.execute_input":"2022-04-16T20:47:26.011757Z","iopub.status.idle":"2022-04-16T20:47:28.102696Z","shell.execute_reply.started":"2022-04-16T20:47:26.011709Z","shell.execute_reply":"2022-04-16T20:47:28.101637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_info = pd.read_csv(base_dir+'full_df.csv')\ntargets = data_info['target']","metadata":{"execution":{"iopub.status.busy":"2022-04-16T20:47:28.104089Z","iopub.execute_input":"2022-04-16T20:47:28.104388Z","iopub.status.idle":"2022-04-16T20:47:28.150342Z","shell.execute_reply.started":"2022-04-16T20:47:28.104346Z","shell.execute_reply":"2022-04-16T20:47:28.149375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"glaucoma = data_info[data_info['G']==1]\nnormal = data_info[data_info['N']==1]","metadata":{"execution":{"iopub.status.busy":"2022-04-16T20:47:28.153597Z","iopub.execute_input":"2022-04-16T20:47:28.1541Z","iopub.status.idle":"2022-04-16T20:47:28.162092Z","shell.execute_reply.started":"2022-04-16T20:47:28.154055Z","shell.execute_reply":"2022-04-16T20:47:28.160607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"normal=normal.sample(frac=0.15,random_state=200) #random state is a seed value\nnormal","metadata":{"execution":{"iopub.status.busy":"2022-04-16T20:47:28.163907Z","iopub.execute_input":"2022-04-16T20:47:28.164509Z","iopub.status.idle":"2022-04-16T20:47:28.204132Z","shell.execute_reply.started":"2022-04-16T20:47:28.164464Z","shell.execute_reply":"2022-04-16T20:47:28.202969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_info = pd.concat([glaucoma,normal])","metadata":{"execution":{"iopub.status.busy":"2022-04-16T20:47:28.205709Z","iopub.execute_input":"2022-04-16T20:47:28.2063Z","iopub.status.idle":"2022-04-16T20:47:28.217497Z","shell.execute_reply.started":"2022-04-16T20:47:28.206255Z","shell.execute_reply":"2022-04-16T20:47:28.215774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df=data_info.sample(frac=0.90,random_state=200) #random state is a seed value\ntest_df=data_info.drop(train_df.index)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T20:47:28.219474Z","iopub.execute_input":"2022-04-16T20:47:28.220035Z","iopub.status.idle":"2022-04-16T20:47:28.230639Z","shell.execute_reply.started":"2022-04-16T20:47:28.219973Z","shell.execute_reply":"2022-04-16T20:47:28.229517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_target(target):\n    target = target.replace('[','').replace(']','')\n    target = target.split(',')\n    target = [int(t.strip()) for t in target]\n    return np.argmax(np.array(target))\n    return target","metadata":{"execution":{"iopub.status.busy":"2022-04-16T20:47:28.232671Z","iopub.execute_input":"2022-04-16T20:47:28.233066Z","iopub.status.idle":"2022-04-16T20:47:28.395713Z","shell.execute_reply.started":"2022-04-16T20:47:28.233021Z","shell.execute_reply":"2022-04-16T20:47:28.394357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_images(image_fnames,images_dir):\n    images = []\n    n = 0\n    for fname in image_fnames:\n        image = cv2.imread(images_dir+fname)\n        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n        images.append(image)\n        print(n); n+=1\n        print(image.shape)\n        if n > 500:\n            break\n    return np.array(images)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T20:47:28.397564Z","iopub.execute_input":"2022-04-16T20:47:28.398621Z","iopub.status.idle":"2022-04-16T20:47:28.409829Z","shell.execute_reply.started":"2022-04-16T20:47:28.398565Z","shell.execute_reply":"2022-04-16T20:47:28.408749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def _bytes_feature(value):\n    if isinstance(value, type(tf.constant(0))): # if value ist tensor\n        value = value.numpy() # get value of tensor\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _float_feature(value):\n    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n\ndef _int64_feature(value):\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\ndef serialize_array(array):\n    array = tf.io.serialize_tensor(array)\n    return array","metadata":{"execution":{"iopub.status.busy":"2022-04-16T20:47:28.411366Z","iopub.execute_input":"2022-04-16T20:47:28.411893Z","iopub.status.idle":"2022-04-16T20:47:28.423245Z","shell.execute_reply.started":"2022-04-16T20:47:28.411845Z","shell.execute_reply":"2022-04-16T20:47:28.421844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def parse_single_image(image, label):\n  #define the dictionary -- the structure -- of our single example\n    data = {\n            'height' : _int64_feature(image.shape[0]),\n            'width' : _int64_feature(image.shape[1]),\n            'depth' : _int64_feature(image.shape[2]),\n            'raw_image' : _bytes_feature(serialize_array(image)),\n            'label' : _int64_feature(label)\n        }\n   #create an Example, wrapping the single features\n    output = tf.train.Example(features=tf.train.Features(feature=data))\n    return output","metadata":{"execution":{"iopub.status.busy":"2022-04-16T20:47:28.42502Z","iopub.execute_input":"2022-04-16T20:47:28.425523Z","iopub.status.idle":"2022-04-16T20:47:28.435962Z","shell.execute_reply.started":"2022-04-16T20:47:28.425478Z","shell.execute_reply":"2022-04-16T20:47:28.434896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def parse_tfr_element(element):\n  #use the same structure as above; it's kinda an outline of the structure we now want to create\n    data = {\n      'height': tf.io.FixedLenFeature([], tf.int64),\n      'width':tf.io.FixedLenFeature([], tf.int64),\n      'label':tf.io.FixedLenFeature([], tf.int64),\n      'raw_image' : tf.io.FixedLenFeature([], tf.string),\n      'depth':tf.io.FixedLenFeature([], tf.int64),\n    }\n    content = tf.io.parse_single_example(element, data)\n  \n    height = content['height']\n    width = content['width']\n    depth = content['depth']\n    label = content['label']\n    raw_image = content['raw_image']\n    #get our 'feature'-- our image -- and reshape it appropriately\n    feature = tf.io.parse_tensor(raw_image, out_type=tf.uint8)\n    feature = tf.reshape(feature, shape=[height,width,depth])\n    feature = tf.image.resize(feature, [256, 256])/255\n    return (feature, label)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T20:50:30.966046Z","iopub.execute_input":"2022-04-16T20:50:30.966338Z","iopub.status.idle":"2022-04-16T20:50:30.976978Z","shell.execute_reply.started":"2022-04-16T20:50:30.966306Z","shell.execute_reply":"2022-04-16T20:50:30.975554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def images2tfrecord(df,filename):\n    #\n    filename= filename+\".tfrecords\"\n    writer = tf.io.TFRecordWriter(filename) #create a writer that'll store our data to disk\n    count = 0\n    for idx,row in df.iterrows():\n        image = cv2.imread(image_dir+row['filename'])\n        current_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        current_label = row['N']\n        #current_label = extract_target(current_label)\n        out = parse_single_image(image=current_image, label=current_label)\n        writer.write(out.SerializeToString())\n        count += 1\n    writer.close()\n    print(f\"Wrote {count} elements to TFRecord\")\n    return count ","metadata":{"execution":{"iopub.status.busy":"2022-04-16T20:50:31.371716Z","iopub.execute_input":"2022-04-16T20:50:31.372301Z","iopub.status.idle":"2022-04-16T20:50:31.38012Z","shell.execute_reply.started":"2022-04-16T20:50:31.372267Z","shell.execute_reply":"2022-04-16T20:50:31.378875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images2tfrecord(train_df,'train_data_record')\nimages2tfrecord(test_df,'test_data_record')","metadata":{"execution":{"iopub.status.busy":"2022-04-16T20:50:33.496223Z","iopub.execute_input":"2022-04-16T20:50:33.496794Z","iopub.status.idle":"2022-04-16T20:50:39.720127Z","shell.execute_reply.started":"2022-04-16T20:50:33.496745Z","shell.execute_reply":"2022-04-16T20:50:39.719041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_image_dataset_train = tf.data.TFRecordDataset('train_data_record.tfrecords')\n\n# Create a dictionary describing the features.\nimage_feature_description = {\n    'height': tf.io.FixedLenFeature([], tf.int64),\n    'width': tf.io.FixedLenFeature([], tf.int64),\n    'depth': tf.io.FixedLenFeature([], tf.int64),\n    'label': tf.io.FixedLenFeature([], tf.int64),\n    'image_raw': tf.io.FixedLenFeature([], tf.string),\n}\n\ndef _parse_image_function(example_proto):\n  # Parse the input tf.train.Example proto using the dictionary above.\n  return tf.io.parse_single_example(example_proto, image_feature_description)\n\nparsed_image_dataset_train = raw_image_dataset_train.map(_parse_image_function)\nraw_image_dataset_test = tf.data.TFRecordDataset('test_data_record.tfrecords')\nparsed_image_dataset_test = raw_image_dataset_test.map(_parse_image_function)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-16T20:51:13.381816Z","iopub.execute_input":"2022-04-16T20:51:13.382145Z","iopub.status.idle":"2022-04-16T20:51:13.434815Z","shell.execute_reply.started":"2022-04-16T20:51:13.382115Z","shell.execute_reply":"2022-04-16T20:51:13.433889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_dataset(filename):\n  #create the dataset\n    dataset = tf.data.TFRecordDataset(filename)\n\n  #pass every single feature through our mapping function\n    dataset = dataset.map(\n      parse_tfr_element\n  ) \n    return dataset","metadata":{"execution":{"iopub.status.busy":"2022-04-16T20:51:13.980681Z","iopub.execute_input":"2022-04-16T20:51:13.98096Z","iopub.status.idle":"2022-04-16T20:51:13.987398Z","shell.execute_reply.started":"2022-04-16T20:51:13.980929Z","shell.execute_reply":"2022-04-16T20:51:13.986297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"map_dataset_train = get_dataset('train_data_record.tfrecords')\nmap_dataset_test = get_dataset('test_data_record.tfrecords')","metadata":{"execution":{"iopub.status.busy":"2022-04-16T20:51:14.246676Z","iopub.execute_input":"2022-04-16T20:51:14.247165Z","iopub.status.idle":"2022-04-16T20:51:14.434975Z","shell.execute_reply.started":"2022-04-16T20:51:14.247118Z","shell.execute_reply":"2022-04-16T20:51:14.434006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for image_features in map_dataset_train:\n    image_raw = image_features[0].numpy()\n    label = image_features[1]\n    print(label)\n    plt.imshow(image_raw)\n    break\n    # to iterate over the dataset","metadata":{"execution":{"iopub.status.busy":"2022-04-16T20:51:16.54162Z","iopub.execute_input":"2022-04-16T20:51:16.541933Z","iopub.status.idle":"2022-04-16T20:51:16.837496Z","shell.execute_reply.started":"2022-04-16T20:51:16.541902Z","shell.execute_reply":"2022-04-16T20:51:16.836508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batched_dataset_train = map_dataset_train.batch(32, drop_remainder=True)\nbatched_dataset_test = map_dataset_test.batch(32, drop_remainder=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T20:51:16.839859Z","iopub.execute_input":"2022-04-16T20:51:16.840228Z","iopub.status.idle":"2022-04-16T20:51:16.849134Z","shell.execute_reply.started":"2022-04-16T20:51:16.840181Z","shell.execute_reply":"2022-04-16T20:51:16.847759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D,Flatten, MaxPool2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import sparse_categorical_crossentropy, CategoricalCrossentropy, binary_crossentropy","metadata":{"execution":{"iopub.status.busy":"2022-04-16T20:51:18.461215Z","iopub.execute_input":"2022-04-16T20:51:18.461563Z","iopub.status.idle":"2022-04-16T20:51:18.469212Z","shell.execute_reply.started":"2022-04-16T20:51:18.461513Z","shell.execute_reply":"2022-04-16T20:51:18.466835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model = tf.keras.applications.VGG19(input_shape=(256,256,3),\n                                               include_top=False,\n                                               weights='imagenet')","metadata":{"execution":{"iopub.status.busy":"2022-04-16T20:57:36.368763Z","iopub.execute_input":"2022-04-16T20:57:36.369092Z","iopub.status.idle":"2022-04-16T20:57:36.798755Z","shell.execute_reply.started":"2022-04-16T20:57:36.369059Z","shell.execute_reply":"2022-04-16T20:57:36.797589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs = tf.keras.Input(shape=(256, 256, 3))\nprediction_layer = tf.keras.layers.Dense(1,activation='sigmoid')\nfc_layer = tf.keras.layers.Dense(256,activation='relu')\nx = base_model(inputs, training=False)\nfor layer in base_model.layers:\n    layer.trainable = False\n    \nx = tf.keras.layers.Dropout(0.2)(x)\nx = Flatten()(x)\nx = fc_layer(x)\n#outputs = prediction_layer(x)\noutputs = prediction_layer(x)\nmodel = tf.keras.Model(inputs, outputs)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T20:57:39.59661Z","iopub.execute_input":"2022-04-16T20:57:39.597776Z","iopub.status.idle":"2022-04-16T20:57:39.707028Z","shell.execute_reply.started":"2022-04-16T20:57:39.597716Z","shell.execute_reply":"2022-04-16T20:57:39.706021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam',loss=binary_crossentropy,metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-04-16T20:57:42.326214Z","iopub.execute_input":"2022-04-16T20:57:42.326729Z","iopub.status.idle":"2022-04-16T20:57:42.343046Z","shell.execute_reply.started":"2022-04-16T20:57:42.326693Z","shell.execute_reply":"2022-04-16T20:57:42.340624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-16T20:57:45.230455Z","iopub.execute_input":"2022-04-16T20:57:45.231486Z","iopub.status.idle":"2022-04-16T20:57:45.247651Z","shell.execute_reply.started":"2022-04-16T20:57:45.231426Z","shell.execute_reply":"2022-04-16T20:57:45.246281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(batched_dataset_train,epochs=15)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T20:57:49.42619Z","iopub.execute_input":"2022-04-16T20:57:49.427146Z","iopub.status.idle":"2022-04-16T20:58:25.53848Z","shell.execute_reply.started":"2022-04-16T20:57:49.427108Z","shell.execute_reply":"2022-04-16T20:58:25.537471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(batched_dataset_test)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T20:58:27.490141Z","iopub.execute_input":"2022-04-16T20:58:27.49047Z","iopub.status.idle":"2022-04-16T20:58:28.068571Z","shell.execute_reply.started":"2022-04-16T20:58:27.490437Z","shell.execute_reply":"2022-04-16T20:58:28.067526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('/kaggle/working/glaucoma_model.h5')","metadata":{"execution":{"iopub.status.busy":"2022-04-16T20:58:59.191313Z","iopub.execute_input":"2022-04-16T20:58:59.191616Z","iopub.status.idle":"2022-04-16T20:58:59.778685Z","shell.execute_reply.started":"2022-04-16T20:58:59.191583Z","shell.execute_reply":"2022-04-16T20:58:59.777646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}