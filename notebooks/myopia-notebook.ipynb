{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimage_dir = '/kaggle/input/ocular-disease-recognition-odir5k/preprocessed_images/'\nbase_dir = '/kaggle/input/ocular-disease-recognition-odir5k/'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-16T22:08:11.242464Z","iopub.execute_input":"2022-04-16T22:08:11.243064Z","iopub.status.idle":"2022-04-16T22:08:11.247477Z","shell.execute_reply.started":"2022-04-16T22:08:11.243022Z","shell.execute_reply":"2022-04-16T22:08:11.246737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\n#from utils import extract_target_array","metadata":{"execution":{"iopub.status.busy":"2022-04-16T22:08:11.249127Z","iopub.execute_input":"2022-04-16T22:08:11.249521Z","iopub.status.idle":"2022-04-16T22:08:15.614009Z","shell.execute_reply.started":"2022-04-16T22:08:11.249487Z","shell.execute_reply":"2022-04-16T22:08:15.613284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_info = pd.read_csv(base_dir+'full_df.csv')\ntargets = data_info['target']","metadata":{"execution":{"iopub.status.busy":"2022-04-16T22:08:15.615345Z","iopub.execute_input":"2022-04-16T22:08:15.615584Z","iopub.status.idle":"2022-04-16T22:08:15.674574Z","shell.execute_reply.started":"2022-04-16T22:08:15.615551Z","shell.execute_reply":"2022-04-16T22:08:15.673871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"myopia = data_info[data_info['M']==1]\nnormal = data_info[data_info['N']==1]","metadata":{"execution":{"iopub.status.busy":"2022-04-16T22:08:15.676217Z","iopub.execute_input":"2022-04-16T22:08:15.676492Z","iopub.status.idle":"2022-04-16T22:08:15.683454Z","shell.execute_reply.started":"2022-04-16T22:08:15.676458Z","shell.execute_reply":"2022-04-16T22:08:15.682663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"normal=normal.sample(frac=0.15,random_state=200) #random state is a seed value\nnormal","metadata":{"execution":{"iopub.status.busy":"2022-04-16T22:08:15.685741Z","iopub.execute_input":"2022-04-16T22:08:15.685998Z","iopub.status.idle":"2022-04-16T22:08:15.718953Z","shell.execute_reply.started":"2022-04-16T22:08:15.685961Z","shell.execute_reply":"2022-04-16T22:08:15.718347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_info = pd.concat([myopia,normal])","metadata":{"execution":{"iopub.status.busy":"2022-04-16T22:08:15.720244Z","iopub.execute_input":"2022-04-16T22:08:15.720499Z","iopub.status.idle":"2022-04-16T22:08:15.726617Z","shell.execute_reply.started":"2022-04-16T22:08:15.720466Z","shell.execute_reply":"2022-04-16T22:08:15.725784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df=data_info.sample(frac=0.90,random_state=200) #random state is a seed value\ntest_df=data_info.drop(train_df.index)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T22:08:15.72806Z","iopub.execute_input":"2022-04-16T22:08:15.728564Z","iopub.status.idle":"2022-04-16T22:08:15.738752Z","shell.execute_reply.started":"2022-04-16T22:08:15.728529Z","shell.execute_reply":"2022-04-16T22:08:15.737984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_target(target):\n    target = target.replace('[','').replace(']','')\n    target = target.split(',')\n    target = [int(t.strip()) for t in target]\n    return np.argmax(np.array(target))\n    return target","metadata":{"execution":{"iopub.status.busy":"2022-04-16T22:08:15.73997Z","iopub.execute_input":"2022-04-16T22:08:15.740511Z","iopub.status.idle":"2022-04-16T22:08:15.745952Z","shell.execute_reply.started":"2022-04-16T22:08:15.740476Z","shell.execute_reply":"2022-04-16T22:08:15.745131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_images(image_fnames,images_dir):\n    images = []\n    n = 0\n    for fname in image_fnames:\n        image = cv2.imread(images_dir+fname)\n        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n        images.append(image)\n        print(n); n+=1\n        print(image.shape)\n        if n > 500:\n            break\n    return np.array(images)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T22:08:15.747174Z","iopub.execute_input":"2022-04-16T22:08:15.747624Z","iopub.status.idle":"2022-04-16T22:08:15.754361Z","shell.execute_reply.started":"2022-04-16T22:08:15.747589Z","shell.execute_reply":"2022-04-16T22:08:15.753735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def _bytes_feature(value):\n    if isinstance(value, type(tf.constant(0))): # if value ist tensor\n        value = value.numpy() # get value of tensor\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _float_feature(value):\n    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n\ndef _int64_feature(value):\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\ndef serialize_array(array):\n    array = tf.io.serialize_tensor(array)\n    return array","metadata":{"execution":{"iopub.status.busy":"2022-04-16T22:08:15.756522Z","iopub.execute_input":"2022-04-16T22:08:15.757795Z","iopub.status.idle":"2022-04-16T22:08:15.76546Z","shell.execute_reply.started":"2022-04-16T22:08:15.757756Z","shell.execute_reply":"2022-04-16T22:08:15.764639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def parse_single_image(image, label):\n  #define the dictionary -- the structure -- of our single example\n    data = {\n            'height' : _int64_feature(image.shape[0]),\n            'width' : _int64_feature(image.shape[1]),\n            'depth' : _int64_feature(image.shape[2]),\n            'raw_image' : _bytes_feature(serialize_array(image)),\n            'label' : _int64_feature(label)\n        }\n   #create an Example, wrapping the single features\n    output = tf.train.Example(features=tf.train.Features(feature=data))\n    return output","metadata":{"execution":{"iopub.status.busy":"2022-04-16T22:08:15.766613Z","iopub.execute_input":"2022-04-16T22:08:15.766979Z","iopub.status.idle":"2022-04-16T22:08:15.776969Z","shell.execute_reply.started":"2022-04-16T22:08:15.766938Z","shell.execute_reply":"2022-04-16T22:08:15.776141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def parse_tfr_element(element):\n  #use the same structure as above; it's kinda an outline of the structure we now want to create\n    data = {\n      'height': tf.io.FixedLenFeature([], tf.int64),\n      'width':tf.io.FixedLenFeature([], tf.int64),\n      'label':tf.io.FixedLenFeature([], tf.int64),\n      'raw_image' : tf.io.FixedLenFeature([], tf.string),\n      'depth':tf.io.FixedLenFeature([], tf.int64),\n    }\n    content = tf.io.parse_single_example(element, data)\n  \n    height = content['height']\n    width = content['width']\n    depth = content['depth']\n    label = content['label']\n    raw_image = content['raw_image']\n    #get our 'feature'-- our image -- and reshape it appropriately\n    feature = tf.io.parse_tensor(raw_image, out_type=tf.uint8)\n    feature = tf.reshape(feature, shape=[height,width,depth])\n    feature = tf.image.resize(feature, [256, 256])/255\n    return (feature, label)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T22:08:15.777863Z","iopub.execute_input":"2022-04-16T22:08:15.779766Z","iopub.status.idle":"2022-04-16T22:08:15.788366Z","shell.execute_reply.started":"2022-04-16T22:08:15.77973Z","shell.execute_reply":"2022-04-16T22:08:15.787681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def images2tfrecord(df,filename):\n    #\n    filename= filename+\".tfrecords\"\n    writer = tf.io.TFRecordWriter(filename) #create a writer that'll store our data to disk\n    count = 0\n    for idx,row in df.iterrows():\n        image = cv2.imread(image_dir+row['filename'])\n        current_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        current_label = row['N']\n        #current_label = extract_target(current_label)\n        out = parse_single_image(image=current_image, label=current_label)\n        writer.write(out.SerializeToString())\n        count += 1\n    writer.close()\n    print(f\"Wrote {count} elements to TFRecord\")\n    return count ","metadata":{"execution":{"iopub.status.busy":"2022-04-16T22:08:15.789651Z","iopub.execute_input":"2022-04-16T22:08:15.79006Z","iopub.status.idle":"2022-04-16T22:08:15.797564Z","shell.execute_reply.started":"2022-04-16T22:08:15.790021Z","shell.execute_reply":"2022-04-16T22:08:15.796776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images2tfrecord(train_df,'train_data_record')\nimages2tfrecord(test_df,'test_data_record')","metadata":{"execution":{"iopub.status.busy":"2022-04-16T22:08:15.800887Z","iopub.execute_input":"2022-04-16T22:08:15.80115Z","iopub.status.idle":"2022-04-16T22:08:25.48628Z","shell.execute_reply.started":"2022-04-16T22:08:15.801099Z","shell.execute_reply":"2022-04-16T22:08:25.485466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_image_dataset_train = tf.data.TFRecordDataset('train_data_record.tfrecords')\n\n# Create a dictionary describing the features.\nimage_feature_description = {\n    'height': tf.io.FixedLenFeature([], tf.int64),\n    'width': tf.io.FixedLenFeature([], tf.int64),\n    'depth': tf.io.FixedLenFeature([], tf.int64),\n    'label': tf.io.FixedLenFeature([], tf.int64),\n    'image_raw': tf.io.FixedLenFeature([], tf.string),\n}\n\ndef _parse_image_function(example_proto):\n  # Parse the input tf.train.Example proto using the dictionary above.\n  return tf.io.parse_single_example(example_proto, image_feature_description)\n\nparsed_image_dataset_train = raw_image_dataset_train.map(_parse_image_function)\nraw_image_dataset_test = tf.data.TFRecordDataset('test_data_record.tfrecords')\nparsed_image_dataset_test = raw_image_dataset_test.map(_parse_image_function)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T22:08:25.48748Z","iopub.execute_input":"2022-04-16T22:08:25.487746Z","iopub.status.idle":"2022-04-16T22:08:25.673121Z","shell.execute_reply.started":"2022-04-16T22:08:25.487712Z","shell.execute_reply":"2022-04-16T22:08:25.672248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_dataset(filename):\n  #create the dataset\n    dataset = tf.data.TFRecordDataset(filename)\n\n  #pass every single feature through our mapping function\n    dataset = dataset.map(\n      parse_tfr_element\n  ) \n    return dataset","metadata":{"execution":{"iopub.status.busy":"2022-04-16T22:08:25.6824Z","iopub.execute_input":"2022-04-16T22:08:25.68491Z","iopub.status.idle":"2022-04-16T22:08:25.753748Z","shell.execute_reply.started":"2022-04-16T22:08:25.68486Z","shell.execute_reply":"2022-04-16T22:08:25.752894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"map_dataset_train = get_dataset('train_data_record.tfrecords')\nmap_dataset_test = get_dataset('test_data_record.tfrecords')","metadata":{"execution":{"iopub.status.busy":"2022-04-16T22:08:25.758967Z","iopub.execute_input":"2022-04-16T22:08:25.761157Z","iopub.status.idle":"2022-04-16T22:08:27.136446Z","shell.execute_reply.started":"2022-04-16T22:08:25.761118Z","shell.execute_reply":"2022-04-16T22:08:27.135541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for image_features in map_dataset_train:\n    image_raw = image_features[0].numpy()\n    label = image_features[1]\n    print(label)\n    plt.imshow(image_raw)\n    break\n    # to iterate over the dataset","metadata":{"execution":{"iopub.status.busy":"2022-04-16T22:08:27.141034Z","iopub.execute_input":"2022-04-16T22:08:27.143182Z","iopub.status.idle":"2022-04-16T22:08:27.544109Z","shell.execute_reply.started":"2022-04-16T22:08:27.143142Z","shell.execute_reply":"2022-04-16T22:08:27.543368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batched_dataset_train = map_dataset_train.batch(32, drop_remainder=True)\nbatched_dataset_test = map_dataset_test.batch(32, drop_remainder=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T22:08:27.545095Z","iopub.execute_input":"2022-04-16T22:08:27.545322Z","iopub.status.idle":"2022-04-16T22:08:27.552693Z","shell.execute_reply.started":"2022-04-16T22:08:27.545289Z","shell.execute_reply":"2022-04-16T22:08:27.552026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D,Flatten, MaxPool2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import sparse_categorical_crossentropy, CategoricalCrossentropy, binary_crossentropy","metadata":{"execution":{"iopub.status.busy":"2022-04-16T22:08:27.554227Z","iopub.execute_input":"2022-04-16T22:08:27.5549Z","iopub.status.idle":"2022-04-16T22:08:28.414034Z","shell.execute_reply.started":"2022-04-16T22:08:27.554861Z","shell.execute_reply":"2022-04-16T22:08:28.413172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model = tf.keras.applications.VGG19(input_shape=(256,256,3),\n                                               include_top=False,\n                                               weights='imagenet')","metadata":{"execution":{"iopub.status.busy":"2022-04-16T22:08:28.415498Z","iopub.execute_input":"2022-04-16T22:08:28.415905Z","iopub.status.idle":"2022-04-16T22:08:29.151966Z","shell.execute_reply.started":"2022-04-16T22:08:28.415867Z","shell.execute_reply":"2022-04-16T22:08:29.151205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs = tf.keras.Input(shape=(256, 256, 3))\nprediction_layer = tf.keras.layers.Dense(1,activation='sigmoid')\nfc_layer = tf.keras.layers.Dense(256,activation='relu')\nx = base_model(inputs, training=False)\nfor layer in base_model.layers:\n    layer.trainable = False\n    \n#x = tf.keras.layers.Dropout(0.4)(x)\nx = Flatten()(x)\n#x = fc_layer(x)\nx = tf.keras.layers.Dropout(0.4)(x)\n#outputs = prediction_layer(x)\noutputs = prediction_layer(x)\nmodel = tf.keras.Model(inputs, outputs)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T22:10:12.749707Z","iopub.execute_input":"2022-04-16T22:10:12.749974Z","iopub.status.idle":"2022-04-16T22:10:12.829411Z","shell.execute_reply.started":"2022-04-16T22:10:12.749939Z","shell.execute_reply":"2022-04-16T22:10:12.828672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam',loss=binary_crossentropy,metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-04-16T22:10:17.1307Z","iopub.execute_input":"2022-04-16T22:10:17.131576Z","iopub.status.idle":"2022-04-16T22:10:17.1433Z","shell.execute_reply.started":"2022-04-16T22:10:17.131528Z","shell.execute_reply":"2022-04-16T22:10:17.142592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-16T22:10:18.449769Z","iopub.execute_input":"2022-04-16T22:10:18.450292Z","iopub.status.idle":"2022-04-16T22:10:18.460184Z","shell.execute_reply.started":"2022-04-16T22:10:18.450257Z","shell.execute_reply":"2022-04-16T22:10:18.459106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(batched_dataset_train,epochs=15,validation_data=batched_dataset_test)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T22:11:37.772063Z","iopub.execute_input":"2022-04-16T22:11:37.772323Z","iopub.status.idle":"2022-04-16T22:12:09.908354Z","shell.execute_reply.started":"2022-04-16T22:11:37.772294Z","shell.execute_reply":"2022-04-16T22:12:09.907521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(batched_dataset_test)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T22:12:14.754393Z","iopub.execute_input":"2022-04-16T22:12:14.754877Z","iopub.status.idle":"2022-04-16T22:12:14.930225Z","shell.execute_reply.started":"2022-04-16T22:12:14.754842Z","shell.execute_reply":"2022-04-16T22:12:14.929494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('/kaggle/working/myopia.h5')","metadata":{"execution":{"iopub.status.busy":"2022-04-16T22:12:37.366221Z","iopub.execute_input":"2022-04-16T22:12:37.366468Z","iopub.status.idle":"2022-04-16T22:12:37.546041Z","shell.execute_reply.started":"2022-04-16T22:12:37.366442Z","shell.execute_reply":"2022-04-16T22:12:37.545231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}